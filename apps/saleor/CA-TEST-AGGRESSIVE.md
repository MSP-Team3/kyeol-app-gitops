# Cluster Autoscaler (CA) í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

## ğŸ¯ í…ŒìŠ¤íŠ¸ ëª©í‘œ

```
[ ê°•í•œ ë¶€í•˜ ë°œìƒ ]
     â†“
[ HPA: Pod 2ê°œ â†’ 10ê°œ ì¦ê°€ ]
     â†“
[ Node ìì› ë¶€ì¡± (CPU/Memory í•œê³„) ]
     â†“
[ Pod Pending ìƒíƒœ ë°œìƒ ]
     â†“
[ Cluster Autoscaler íŒë‹¨ ]
     â†“
[ ìƒˆë¡œìš´ Node ì¶”ê°€ ]
     â†“
[ Pending Pod ìŠ¤ì¼€ì¤„ë§ ì™„ë£Œ ]
```

## ğŸ“‹ ì „ì œ ì¡°ê±´

### 1. Cluster Autoscaler ì„¤ì¹˜ í™•ì¸

```bash
# CA í™•ì¸
kubectl get deployment cluster-autoscaler -n kube-system

# CA ë¡œê·¸ í™•ì¸
kubectl logs -n kube-system -l app=cluster-autoscaler --tail=50
```

### 2. Node Group í™•ì¸ (AWS EKS ê¸°ì¤€)

```bash
# Node í˜„í™©
kubectl get nodes

# Node ë¦¬ì†ŒìŠ¤ í™•ì¸
kubectl top nodes
```

### 3. HPA ë¦¬ì†ŒìŠ¤ ì¦ê°€ (ë” ë¹ ë¥¸ Pod ì¦ê°€)

í˜„ì¬ HPA ì„¤ì •ì„ ë” ê³µê²©ì ìœ¼ë¡œ ìˆ˜ì •:

```yaml
# hpa-storefront.yaml ìˆ˜ì •
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: storefront-hpa
  namespace: kyeol
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: storefront
  minReplicas: 2
  maxReplicas: 20  # 10 â†’ 20 (ë” ë§ì€ Pod)
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50  # 70% â†’ 50% (ë” ë¹ ë¥¸ íŠ¸ë¦¬ê±°)
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0  # 30ì´ˆ â†’ 0ì´ˆ (ì¦‰ì‹œ)
      policies:
        - type: Percent
          value: 200  # 100% â†’ 200% (ë” ë¹ ë¥¸ ì¦ê°€)
          periodSeconds: 10  # 15ì´ˆ â†’ 10ì´ˆ
        - type: Pods
          value: 5  # 2ê°œ â†’ 5ê°œ (í•œ ë²ˆì— ë” ë§ì´)
          periodSeconds: 10
      selectPolicy: Max
```

## ğŸš€ Step-by-Step í…ŒìŠ¤íŠ¸

### Step 1: ë¦¬ì†ŒìŠ¤ ìš”ì²­ëŸ‰ ì¦ê°€ (Podê°€ ë” ë§ì€ ìì› í•„ìš”)

```yaml
# deployment-storefront.yaml ìˆ˜ì •
resources:
  requests:
    cpu: 500m      # 100m â†’ 500m (ë” ë§ì€ CPU ìš”ì²­)
    memory: 512Mi  # 128Mi â†’ 512Mi (ë” ë§ì€ ë©”ëª¨ë¦¬ ìš”ì²­)
  limits:
    cpu: 1000m     # 500m â†’ 1000m
    memory: 1Gi    # 512Mi â†’ 1Gi
```

ì´ë ‡ê²Œ í•˜ë©´ Node ë‹¹ ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” Pod ìˆ˜ê°€ ì¤„ì–´ë“¤ì–´ ë¹¨ë¦¬ Node í•œê³„ì— ë„ë‹¬í•©ë‹ˆë‹¤.

### Step 2: GitOps ì ìš©

```bash
cd D:\4th_Parkminwook\WORKSPACE\kyeol-project\kyeol-app-gitops

# ë³€ê²½ ì‚¬í•­ ì»¤ë°‹
git add apps/saleor/base/
git commit -m "feat: Increase HPA limits and Pod resources for CA test

- HPA maxReplicas: 10 â†’ 20
- HPA CPU threshold: 70% â†’ 50%
- HPA scaleUp: more aggressive (200%, 5 pods)
- Pod CPU request: 100m â†’ 500m
- Pod Memory request: 128Mi â†’ 512Mi"

git push origin main

# ArgoCD ë™ê¸°í™”
argocd app sync saleor
```

### Step 3: ëª¨ë‹ˆí„°ë§ ì¤€ë¹„ (5ê°œ í„°ë¯¸ë„)

#### Terminal 1: HPA ìƒíƒœ
```bash
watch -n 1 'kubectl get hpa storefront-hpa -n kyeol'
```

#### Terminal 2: Pod ìƒíƒœ (Pending í™•ì¸)
```bash
watch -n 1 'kubectl get pods -n kyeol -l app=storefront -o wide'
```

#### Terminal 3: Node ìƒíƒœ
```bash
watch -n 2 'kubectl get nodes'
```

#### Terminal 4: Node ë¦¬ì†ŒìŠ¤
```bash
watch -n 2 'kubectl top nodes'
```

#### Terminal 5: CA ë¡œê·¸
```bash
kubectl logs -n kube-system -l app=cluster-autoscaler -f
```

### Step 4: ì´ˆê°•ë ¥ ë¶€í•˜ í…ŒìŠ¤íŠ¸

#### ë°©ë²• 1: k6 (ë§¤ìš° ê°•í•œ ë¶€í•˜)

`loadtest-ca-aggressive.js`:

```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '30s', target: 50 },
    { duration: '1m', target: 200 },   // ë¹ ë¥´ê²Œ 200 VUs
    { duration: '3m', target: 500 },   // 500 VUs (ë§¤ìš° ê°•í•¨)
    { duration: '2m', target: 1000 },  // 1000 VUs (ìµœëŒ€ ë¶€í•˜)
    { duration: '3m', target: 500 },
    { duration: '1m', target: 0 },
  ],
};

const BASE_URL = 'https://origin-dev.kyeol.click';

export default function () {
  // ì—¬ëŸ¬ í˜ì´ì§€ ë™ì‹œ ìš”ì²­ìœ¼ë¡œ CPU ë¶€í•˜ ì¦ê°€
  http.batch([
    ['GET', `${BASE_URL}/`],
    ['GET', `${BASE_URL}/default-channel/products`],
    ['GET', `${BASE_URL}/default-channel/search`],
  ]);

  sleep(0.5);  // ì§§ì€ ëŒ€ê¸°ë¡œ ìš”ì²­ ë¹ˆë„ ì¦ê°€
}
```

ì‹¤í–‰:
```bash
k6 run loadtest-ca-aggressive.js
```

#### ë°©ë²• 2: hey (ë” ê°„ë‹¨)

```bash
# 500 ë™ì‹œ ì—°ê²°, 10ë¶„ê°„ ì§€ì†
hey -z 10m -c 500 https://origin-dev.kyeol.click/
```

#### ë°©ë²• 3: ë‹¤ì¤‘ AB (ì—¬ëŸ¬ ê°œ ë™ì‹œ ì‹¤í–‰)

```bash
# 5ê°œì˜ ABë¥¼ ë™ì‹œì— ì‹¤í–‰
for i in {1..5}; do
  ab -n 100000 -c 200 https://origin-dev.kyeol.click/ &
done
```

### Step 5: ê´€ì°° í¬ì¸íŠ¸

#### 1ë‹¨ê³„: HPA ì‘ë™ (1-2ë¶„)
```bash
# Pod ì¦ê°€ í™•ì¸
kubectl get pods -n kyeol -l app=storefront

# ê¸°ëŒ€: 2 â†’ 4 â†’ 8 â†’ 12 â†’ 16 â†’ 20 Pods
```

#### 2ë‹¨ê³„: Node ìì› í•œê³„ ë„ë‹¬ (3-5ë¶„)
```bash
# Node CPU/Memory ì‚¬ìš©ë¥  í™•ì¸
kubectl top nodes

# ê¸°ëŒ€: CPU/Memory 80-90% ì‚¬ìš©
```

#### 3ë‹¨ê³„: Pod Pending ë°œìƒ (5-7ë¶„)
```bash
# Pending Pod í™•ì¸
kubectl get pods -n kyeol -l app=storefront | grep Pending

# ìƒì„¸ í™•ì¸
kubectl describe pod <pending-pod-name> -n kyeol

# ê¸°ëŒ€ ë©”ì‹œì§€:
# "0/3 nodes are available: 3 Insufficient cpu."
# ë˜ëŠ”
# "0/3 nodes are available: 3 Insufficient memory."
```

#### 4ë‹¨ê³„: CA íŒë‹¨ (7-8ë¶„)
```bash
# CA ë¡œê·¸ì—ì„œ í™•ì¸
kubectl logs -n kube-system -l app=cluster-autoscaler --tail=100

# ê¸°ëŒ€ ë¡œê·¸:
# "Scale-up: group <node-group> size set to 4"
```

#### 5ë‹¨ê³„: Node ì¦ê°€ (8-10ë¶„)
```bash
# ìƒˆë¡œìš´ Node í™•ì¸
kubectl get nodes -w

# ê¸°ëŒ€: Node 3ê°œ â†’ 4ê°œ â†’ 5ê°œ
```

#### 6ë‹¨ê³„: Pending í•´ì†Œ (10-12ë¶„)
```bash
# ëª¨ë“  Pod Running í™•ì¸
kubectl get pods -n kyeol -l app=storefront

# ê¸°ëŒ€: Pending 0ê°œ, Running 20ê°œ
```

## ğŸ“Š ìƒì„¸ ëª¨ë‹ˆí„°ë§ ëª…ë ¹ì–´

### í•œ ë²ˆì— ëª¨ë“  ì •ë³´ í™•ì¸

```bash
# ì¢…í•© ìƒíƒœ ìŠ¤í¬ë¦½íŠ¸
watch -n 2 '
echo "=== HPA Status ==="
kubectl get hpa storefront-hpa -n kyeol

echo ""
echo "=== Pod Status ==="
kubectl get pods -n kyeol -l app=storefront | head -n 25

echo ""
echo "=== Pod Count ==="
echo "Running: $(kubectl get pods -n kyeol -l app=storefront --field-selector=status.phase=Running --no-headers | wc -l)"
echo "Pending: $(kubectl get pods -n kyeol -l app=storefront --field-selector=status.phase=Pending --no-headers | wc -l)"

echo ""
echo "=== Node Status ==="
kubectl get nodes

echo ""
echo "=== Node Resources ==="
kubectl top nodes
'
```

### Pending Pod ìƒì„¸ ë¶„ì„

```bash
# Pending Pod ì´ìœ  í™•ì¸
for pod in $(kubectl get pods -n kyeol -l app=storefront --field-selector=status.phase=Pending -o name); do
  echo "=== $pod ==="
  kubectl describe $pod -n kyeol | grep -A 10 "Events:"
  echo ""
done
```

### CA ìƒíƒœ í™•ì¸

```bash
# CA ConfigMap í™•ì¸
kubectl get configmap cluster-autoscaler-status -n kube-system -o yaml

# CA ìµœê·¼ ì´ë²¤íŠ¸
kubectl get events -n kube-system --field-selector involvedObject.name=cluster-autoscaler --sort-by='.lastTimestamp'
```

## ğŸ”¥ ë” ë¹ ë¥¸ CA íŠ¸ë¦¬ê±° ë°©ë²•

### ë°©ë²• 1: ìˆ˜ë™ìœ¼ë¡œ ëŒ€ëŸ‰ Pod ìƒì„±

```bash
# Deployment replicas ê°•ì œ ì¦ê°€
kubectl scale deployment storefront -n kyeol --replicas=30

# ê²°ê³¼: ì¦‰ì‹œ 30ê°œ Pod ìƒì„± ì‹œë„ â†’ Node ë¶€ì¡± â†’ CA ì‘ë™
```

### ë°©ë²• 2: ì„ì‹œ Stress Pod ì¶”ê°€ ìƒì„±

```yaml
# stress-test.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: stress-test
  namespace: kyeol
spec:
  replicas: 10
  selector:
    matchLabels:
      app: stress-test
  template:
    metadata:
      labels:
        app: stress-test
    spec:
      containers:
      - name: stress
        image: polinux/stress
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        command: ["stress"]
        args: ["--cpu", "2", "--timeout", "600s"]
```

ì ìš©:
```bash
kubectl apply -f stress-test.yaml

# Node ë¶€ì¡± ì¦‰ì‹œ ë°œìƒ â†’ CA ì‘ë™

# í…ŒìŠ¤íŠ¸ í›„ ì‚­ì œ
kubectl delete -f stress-test.yaml
```

## ğŸ“ˆ ì˜ˆìƒ íƒ€ì„ë¼ì¸

| ì‹œê°„ | ì´ë²¤íŠ¸ | í™•ì¸ ë°©ë²• |
|------|--------|-----------|
| 0:00 | ë¶€í•˜ ì‹œì‘ | k6 ì‹¤í–‰ |
| 0:30 | HPA íŠ¸ë¦¬ê±° (CPU 50% ì´ˆê³¼) | `kubectl get hpa` |
| 1:00 | Pod 2 â†’ 6 ì¦ê°€ | `kubectl get pods` |
| 2:00 | Pod 6 â†’ 12 ì¦ê°€ | `kubectl get pods` |
| 3:00 | Pod 12 â†’ 18 ì¦ê°€ | `kubectl get pods` |
| 4:00 | Node CPU/Memory 90% ë„ë‹¬ | `kubectl top nodes` |
| 5:00 | **Pod Pending ë°œìƒ** | `kubectl get pods \| grep Pending` |
| 6:00 | **CA íŒë‹¨ ì‹œì‘** | CA ë¡œê·¸ |
| 7:00 | **Node ì¶”ê°€ ì‹œì‘** | `kubectl get nodes` |
| 9:00 | **ìƒˆ Node Ready** | `kubectl get nodes` |
| 10:00 | **Pending Pod Running** | `kubectl get pods` |
| 12:00 | ë¶€í•˜ ì¢…ë£Œ | k6 ì™„ë£Œ |
| 17:00 | Pod ê°ì†Œ ì‹œì‘ (5ë¶„ ì•ˆì •í™”) | `kubectl get pods` |
| 25:00 | Pod 2ê°œë¡œ ë³µê·€ | `kubectl get pods` |
| 35:00 | Node ê°ì†Œ ì‹œì‘ (CA scale-down) | `kubectl get nodes` |

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: Podê°€ Pending ì•ˆ ë¨

**ì›ì¸**: Nodeì— ì—¬ìœ  ìì›ì´ ë§ìŒ

**í•´ê²°**:
```bash
# 1. Pod ë¦¬ì†ŒìŠ¤ ìš”ì²­ ë” ì¦ê°€
resources:
  requests:
    cpu: 1000m      # 500m â†’ 1000m
    memory: 1Gi     # 512Mi â†’ 1Gi

# 2. ë˜ëŠ” HPA maxReplicas ë” ì¦ê°€
maxReplicas: 50  # 20 â†’ 50
```

### ë¬¸ì œ 2: CAê°€ ì‘ë™ ì•ˆ í•¨

```bash
# CA ì„¤ì¹˜ í™•ì¸
kubectl get deployment cluster-autoscaler -n kube-system

# CA ì„¤ì • í™•ì¸
kubectl describe deployment cluster-autoscaler -n kube-system

# AWS Node Group í™•ì¸ (EKS)
aws autoscaling describe-auto-scaling-groups --region ap-northeast-2

# CAê°€ Node Group ì¸ì‹í•˜ëŠ”ì§€ í™•ì¸
kubectl logs -n kube-system -l app=cluster-autoscaler | grep "Discovering"
```

### ë¬¸ì œ 3: Node ì¶”ê°€ê°€ ë„ˆë¬´ ëŠë¦¼

**ì›ì¸**: AWS EC2 ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘ ì‹œê°„ (2-5ë¶„)

**í•´ê²°**: ê¸°ë‹¤ë¦¬ê¸° ë˜ëŠ” Warm Pool ì‚¬ìš©

### ë¬¸ì œ 4: Pending Podê°€ ê³„ì† Pending

```bash
# Pod ì´ë²¤íŠ¸ í™•ì¸
kubectl describe pod <pending-pod> -n kyeol

# ì¼ë°˜ì ì¸ ì›ì¸:
# 1. Nodeì˜ ì‹¤ì œ ê°€ìš© ë¦¬ì†ŒìŠ¤ ë¶€ì¡±
# 2. Nodeì— Taint ìˆìŒ
# 3. Podì— NodeSelector/Affinity ìˆìŒ
# 4. CAê°€ ë¹„í™œì„±í™”ë¨
```

## ğŸ“Š ì„±ê³µ ê¸°ì¤€

í…ŒìŠ¤íŠ¸ ì„±ê³µìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ê¸°ì¤€:

- âœ… HPAë¡œ Podê°€ 2 â†’ 20ê°œ ì¦ê°€
- âœ… Node CPU/Memory 90% ì´ìƒ ë„ë‹¬
- âœ… Pod Pending ìƒíƒœ ë°œìƒ
- âœ… CA ë¡œê·¸ì— "Scale-up" ë©”ì‹œì§€
- âœ… Node ê°œìˆ˜ ì¦ê°€ (ì˜ˆ: 3 â†’ 5)
- âœ… Pending Podê°€ Runningìœ¼ë¡œ ì „í™˜
- âœ… ë¶€í•˜ ì¢…ë£Œ í›„ Pod/Node ê°ì†Œ

## ğŸ“ ì¦‰ì‹œ ì‹¤í–‰ ëª…ë ¹ì–´

```bash
# 1. HPA/Deployment ìˆ˜ì • (GitOps)
cd kyeol-app-gitops
# (ìœ„ Step 1, 2 ë‚´ìš© ë°˜ì˜ í›„)
git add . && git commit -m "feat: Aggressive HPA/Pod for CA test" && git push
argocd app sync saleor

# 2. ëª¨ë‹ˆí„°ë§ ì‹œì‘ (5ê°œ í„°ë¯¸ë„)
# Terminal 1
watch -n 1 'kubectl get hpa storefront-hpa -n kyeol'

# Terminal 2
watch -n 1 'kubectl get pods -n kyeol -l app=storefront'

# Terminal 3
watch -n 2 'kubectl get nodes'

# Terminal 4
watch -n 2 'kubectl top nodes'

# Terminal 5
kubectl logs -n kube-system -l app=cluster-autoscaler -f

# 3. ê°•ë ¥í•œ ë¶€í•˜ ì‹œì‘
hey -z 10m -c 500 https://origin-dev.kyeol.click/

# ë˜ëŠ” ìˆ˜ë™ ìŠ¤ì¼€ì¼
kubectl scale deployment storefront -n kyeol --replicas=30
```

---

**ëª©í‘œ**: Node ìì› ì†Œì§„ â†’ Pod Pending â†’ CA Node ì¶”ê°€ í™•ì¸
**ì˜ˆìƒ ì‹œê°„**: 10-15ë¶„
